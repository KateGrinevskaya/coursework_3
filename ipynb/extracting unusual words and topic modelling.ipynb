{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Все необходимые пипы и импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "m = Mystem()\n",
    "import string\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import tokenize\n",
    "from gensim.summarization.textcleaner import split_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import json\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "from nltk.collocations import BigramAssocMeasures, TrigramAssocMeasures, BigramCollocationFinder, TrigramCollocationFinder\n",
    "import re\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from natasha import (\n",
    "    Segmenter,\n",
    "    MorphVocab,\n",
    "    \n",
    "    NewsEmbedding,\n",
    "    NewsMorphTagger,\n",
    "    NewsSyntaxParser,\n",
    "    NewsNERTagger,\n",
    "    \n",
    "    PER,\n",
    "    NamesExtractor,\n",
    "\n",
    "    Doc\n",
    ")\n",
    "\n",
    "\n",
    "segmenter = Segmenter()\n",
    "morph_vocab = MorphVocab()\n",
    "\n",
    "emb = NewsEmbedding()\n",
    "morph_tagger = NewsMorphTagger(emb)\n",
    "syntax_parser = NewsSyntaxParser(emb)\n",
    "ner_tagger = NewsNERTagger(emb)\n",
    "\n",
    "names_extractor = NamesExtractor(morph_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предобработка для работы со словами"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для разметки именованных сущностей, токенизации и удаления стоп-слов из файлов с текстами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_tokens_from_dir(papka: str, sec_name: str):\n",
    "    for f in os.listdir(papka):\n",
    "        f = os.path.join(papka, f)\n",
    "        with open(f, encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "        doc = Doc(text)\n",
    "        doc.segment(segmenter)\n",
    "        doc.tag_ner(ner_tagger)\n",
    "        ents = [span.text.lower() for span in doc.spans]\n",
    "        tokens_gen = tokenize(text, lowercase=True)\n",
    "        tokens = []\n",
    "        for token in tokens_gen:\n",
    "            if token not in russian_stopwords and token not in ents:\n",
    "                tokens.append(token)\n",
    "        tokens_str = ' '.join(tokens)\n",
    "        with open(f'{sec_name}.txt', 'a', encoding='utf-8') as fi:\n",
    "            fi.write(tokens_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запись токенов в файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_tokens(author: str, sec_name: str, e: bool):\n",
    "    if e is False:\n",
    "        write_tokens_from_dir(author, sec_name)\n",
    "    else:\n",
    "        author_before = os.path.join(author, 'до эмиграции')\n",
    "        author_after = os.path.join(author, 'после эмиграции')\n",
    "        sec_name_before = sec_name+'_до'\n",
    "        sec_name_after = sec_name+'_после'\n",
    "        write_tokens_from_dir(author_before, sec_name_before)\n",
    "        write_tokens_from_dir(author_after, sec_name_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "soviet = ['Булгаков', 'Шолохов', 'Фадеев', 'Платонов', 'Стругацкие']\n",
    "emig = ['Солженицын', 'Бунин', 'Зайцев', 'Ремизов', 'Шмелёв']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "for auth in soviet:\n",
    "    author = os.path.join('D:\\курсовая_3', auth)\n",
    "    get_all_tokens(author, auth, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ee4a0c3cec04ee78f195b9080a24db2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for auth in tqdm(emig):\n",
    "    author = os.path.join('D:\\курсовая_3', auth)\n",
    "    get_all_tokens(author, auth, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подсчёт токенов для каждого автора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth_NumOfTok = {}\n",
    "for a in soviet:\n",
    "    with open(f'{a}.txt', encoding='utf-8') as fil:\n",
    "        text = fil.read()\n",
    "        tokens = text.split()\n",
    "        auth_NumOfTok[a] = len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in emig:\n",
    "    auth_NumOfTok[b] = {}\n",
    "    with open(f'{b}_до.txt', encoding='utf-8') as fil:\n",
    "        text = fil.read()\n",
    "        tokens = text.split()\n",
    "        auth_NumOfTok[b]['до'] = len(tokens)\n",
    "    with open(f'{b}_после.txt', encoding='utf-8') as fil:\n",
    "        text = fil.read()\n",
    "        auth_NumOfTok[b]['после'] = len(text.split())\n",
    "        auth_NumOfTok[b]['всего'] = auth_NumOfTok[b]['до'] + auth_NumOfTok[b]['после']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Булгаков': 254748,\n",
       " 'Шолохов': 439344,\n",
       " 'Фадеев': 225490,\n",
       " 'Платонов': 247558,\n",
       " 'Стругацкие': 1237595,\n",
       " 'Солженицын': {'до': 502870, 'после': 308324, 'всего': 811194},\n",
       " 'Бунин': {'до': 58995, 'после': 110018, 'всего': 169013},\n",
       " 'Зайцев': {'до': 73017, 'после': 294319, 'всего': 367336},\n",
       " 'Ремизов': {'до': 156316, 'после': 82127, 'всего': 238443},\n",
       " 'Шмелёв': {'до': 154873, 'после': 250581, 'всего': 405454}}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auth_NumOfTok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лемматизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "756cd7e68f8a4b0da7b99f9edd5c23c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for a in tqdm(soviet):\n",
    "    with open(f'{a}.txt', encoding='utf-8') as fil:\n",
    "        text = fil.read()\n",
    "        lem_text_list = m.lemmatize(text)\n",
    "        lem_text = ''.join(lem_text_list)\n",
    "    with open(f'{a}_леммы.txt', 'a', encoding='utf-8') as fil:\n",
    "        fil.write(lem_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94c5d159fe324c8e8c6058cba5aaa994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for b in tqdm(emig):\n",
    "    with open(f'{b}_до.txt', encoding='utf-8') as fil:\n",
    "        text = fil.read()\n",
    "        lem_text_list = m.lemmatize(text)\n",
    "        lem_text = ''.join(lem_text_list)\n",
    "    with open(f'{b}_до_леммы.txt', 'a', encoding='utf-8') as fil:\n",
    "        fil.write(lem_text)\n",
    "    with open(f'{b}_после.txt', encoding='utf-8') as fil:\n",
    "        text = fil.read()\n",
    "        lem_text_list_2 = m.lemmatize(text)\n",
    "        lem_text_2 = ''.join(lem_text_list_2)\n",
    "    with open(f'{b}_после_леммы.txt', 'a', encoding='utf-8') as fil:\n",
    "        fil.write(lem_text_2)\n",
    "    with open(f'{b}_леммы.txt', 'a', encoding='utf-8') as fil:\n",
    "        fil.write(lem_text+lem_text_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стругацких пришлось лемматизировать по частям - не хватало мощности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Стругацкие.txt', encoding='utf-8') as fil:\n",
    "    text = fil.read()\n",
    "    l = len(text) + 1 \n",
    "part1 = text[0:l//2]\n",
    "part2 = text[l//2:]\n",
    "lem_text_1_list = m.lemmatize(part1)\n",
    "lem_text_2_list = m.lemmatize(part1)\n",
    "lem_text_1 = ''.join(lem_text_1_list)\n",
    "lem_text_2 = ''.join(lem_text_2_list)\n",
    "lem_text = lem_text_1 + lem_text_2\n",
    "with open('Стругацкие_леммы.txt', 'a', encoding='utf-8') as fil:\n",
    "    fil.write(lem_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c24e4545842e4c5681111d38f9ab0e1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = []\n",
    "all_texts = soviet + emig\n",
    "for a in tqdm(all_texts):\n",
    "    with open(f'{a}_леммы.txt', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "        corpus.append(text)\n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Эксперименты со словами"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Эксперимент 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Корпус: 10 документов – по одному на каждого автора. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(sublinear_tf=True)\n",
    "tfidf_matrix = vectorizer.fit_transform(corpus)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = tfidf_matrix.todense()\n",
    "denselist = dense.tolist()\n",
    "df = pd.DataFrame(denselist, columns=feature_names, index=all_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac6dd73576824c1eacc0c6b259596091",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for a in tqdm(all_texts):\n",
    "    with open(f'{a}_100.txt', 'a', encoding='utf-8') as f:\n",
    "        n = pd.Series(df.loc[f'{a}'])\n",
    "        f.write(n[n > 0].sort_values(ascending=False)[:100].to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Эксперимент 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Корпус: 5 документов советских писателей, 5 документов - тексты эмигрантов до эмиграции и 1 документ – тексты всех эмигрантов после эмиграции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f838ac3ddbce45419e5b2a99d2d2aa07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd483811d59c43dfae951b672fcd5de6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "corpus2 = []\n",
    "emig_after = ''\n",
    "index2 = []\n",
    "\n",
    "for b in tqdm(emig):\n",
    "    with open (f'{b}_после_леммы.txt', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    emig_after = ''.join(text)\n",
    "    with open(f'{b}_до_леммы.txt', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "        corpus2.append(text)\n",
    "    index2.append(b)\n",
    "with open('Эмигранты_после.txt', 'a', encoding='utf-8') as f:\n",
    "    f.write(emig_after)\n",
    "    index2.append('Эмигранты')\n",
    "\n",
    "corpus2.append(emig_after)\n",
    "\n",
    "for a in tqdm(soviet):\n",
    "    with open(f'{a}_леммы.txt', encoding='utf-8') as fil:\n",
    "        text = fil.read()\n",
    "    corpus2.append(text)\n",
    "    index2.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(sublinear_tf=True)\n",
    "tfidf_matrix = vectorizer.fit_transform(corpus2)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = tfidf_matrix.todense()\n",
    "denselist = dense.tolist()\n",
    "df2 = pd.DataFrame(denselist, columns=feature_names, index=index2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Эмигранты_после_100.txt', 'a', encoding='utf-8') as f:\n",
    "    n = pd.Series(df2.loc['Эмигранты'])\n",
    "    f.write(n[n > 0].sort_values(ascending=False)[:100].to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Эксперимент 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 небольших экспериментов: для каждого эмигранта корпус состоит из 5 документов советских писателей и 1 документа – текстов каждого эмигранта до эмиграции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auth_vs_sov(em):\n",
    "    indexi = soviet\n",
    "    indexi.append(em)\n",
    "    corpusi = []\n",
    "    for a in indexi:\n",
    "        if a == indexi[-1]:\n",
    "             with open(f'{a}_до_леммы.txt', encoding='utf-8') as fil:\n",
    "                    text = fil.read()\n",
    "        else:\n",
    "            with open(f'{a}_леммы.txt', encoding='utf-8') as fil:\n",
    "                text = fil.read()\n",
    "        corpusi.append(text)\n",
    "    vectorizer = TfidfVectorizer(sublinear_tf=True)\n",
    "    tfidf_matrix = vectorizer.fit_transform(corpusi)\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    dense = tfidf_matrix.todense()\n",
    "    denselist = dense.tolist()\n",
    "    dfi = pd.DataFrame(denselist, columns=feature_names, index=indexi)\n",
    "    with open(f'{em}_до_vs_soviet_100.txt', 'a', encoding='utf-8') as f:\n",
    "        n = pd.Series(dfi.loc[f'{em}'])\n",
    "        f.write(n[n > 0].sort_values(ascending=False)[:100].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e04e37c66f6749c9b7dde7262da2883f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for em in tqdm(emig):\n",
    "    auth_vs_sov(em)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Эксперимент 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 небольших экспериментов для каждого автора-эмигранта: корпус состоял из 5 документов советских писателей, 5 документов писателей-эмигрантов до эмиграции и 1 документа с текстами автора-эмигранта, написанными после эмиграции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def after_vs_before_and_sov(em):\n",
    "    indexi = []\n",
    "    corpusi = []\n",
    "    for a in emig:\n",
    "        indexi.append(a)\n",
    "        with open(f'{a}_до_леммы.txt', encoding='utf-8') as fil:\n",
    "            text = fil.read()\n",
    "        corpusi.append(text)\n",
    "    for a in soviet:\n",
    "        indexi.append(a)\n",
    "        with open(f'{a}_леммы.txt', encoding='utf-8') as fil:\n",
    "            text = fil.read()\n",
    "        corpusi.append(text)\n",
    "    with open(f'{em}_после_леммы.txt', encoding='utf-8') as fil:\n",
    "        text = fil.read()\n",
    "        corpusi.append(text)\n",
    "        indexi.append(f'{em}_после')\n",
    "    vectorizer = TfidfVectorizer(sublinear_tf=True)\n",
    "    tfidf_matrix = vectorizer.fit_transform(corpusi)\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    dense = tfidf_matrix.todense()\n",
    "    denselist = dense.tolist()\n",
    "    dfi = pd.DataFrame(denselist, columns=feature_names, index=indexi)\n",
    "    with open(f'{em}_vs_before_and_sov_100.txt', 'a', encoding='utf-8') as f:\n",
    "        n = pd.Series(dfi.loc[f'{em}_после'])\n",
    "        f.write(n[n > 0].sort_values(ascending=False)[:100].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88774a61de5443e18d5c5eae214497b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for em in tqdm(emig):\n",
    "    after_vs_before_and_sov(em)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Эксперимент 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Корпус – 5 текстов советских писателей в 1 документе, и 5 документов – текстов эмигрантов после эмиграции. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42a12ca820da4092bd568034d21f4a38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "index3 = emig\n",
    "corpus3 = []\n",
    "for a in tqdm(index3):\n",
    "    with open(f'{a}_после_леммы.txt', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    corpus3.append(text)\n",
    "index3.append('Советские')\n",
    "all_sov = ''\n",
    "for b in soviet:\n",
    "    with open(f'{b}_леммы.txt', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    all_sov = ''.join(text)\n",
    "corpus3.append(all_sov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(sublinear_tf=True)\n",
    "tfidf_matrix = vectorizer.fit_transform(corpus3)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = tfidf_matrix.todense()\n",
    "denselist = dense.tolist()\n",
    "df3 = pd.DataFrame(denselist, columns=feature_names, index=index3)\n",
    "with open('soviet_vs_emig_after_100.txt', 'a', encoding='utf-8') as f:\n",
    "    n = pd.Series(df3.loc[f'{index3[-1]}'])\n",
    "    f.write(n[n > 0].sort_values(ascending=False)[:100].to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Много слов Стругацких, посмотрим без них. Корпус – 4 текста советских писателей в 1 документе, и 5 документов – текстов эмигрантов после эмиграции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "143cae1b83a749d198174a6a86f16170",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "index7 = emig\n",
    "corpus7 = []\n",
    "for a in tqdm(index7):\n",
    "    with open(f'{a}_после_леммы.txt', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    corpus7.append(text)\n",
    "index7.append('Советские')\n",
    "all_sov_wo_stru = ''\n",
    "for b in soviet:\n",
    "    if b != 'Стругацкие':\n",
    "        with open(f'{b}_леммы.txt', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "        all_sov_wo_stru = ''.join(text)\n",
    "corpus7.append(all_sov_wo_stru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(sublinear_tf=True)\n",
    "tfidf_matrix = vectorizer.fit_transform(corpus7)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = tfidf_matrix.todense()\n",
    "denselist = dense.tolist()\n",
    "df7 = pd.DataFrame(denselist, columns=feature_names, index=index7)\n",
    "with open('soviet_woStrug_vs_emig_after_100.txt', 'a', encoding='utf-8') as f:\n",
    "    n = pd.Series(df7.loc[f'{index7[-1]}'])\n",
    "    f.write(n[n > 0].sort_values(ascending=False)[:100].to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Эксперименты с биграммами и триграммами"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаю объект, где хранятся всякие метрики для биграмм (bigram_measures). В finder_sov хранятся все биграммы произведений советских писателей. В sov_len хранится количество всех биграмм."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Солженицын.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-96-a5c190966da6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Солженицын.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mbigram_measures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBigramAssocMeasures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfinder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBigramCollocationFinder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_words\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinder\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Солженицын.txt'"
     ]
    }
   ],
   "source": [
    "with open('Солженицын.txt', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "bigram_measures = BigramAssocMeasures()\n",
    "finder = BigramCollocationFinder.from_words(text)\n",
    "print(finder[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Топики"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Советские писатели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemm_stories(papka: str):\n",
    "    auth_lemmas = []\n",
    "    for f in os.listdir(papka):\n",
    "        f = os.path.join(papka, f)\n",
    "        with open(f, encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "        doc = Doc(text)\n",
    "        doc.segment(segmenter)\n",
    "        doc.tag_morph(morph_tagger)\n",
    "        lemmas = []\n",
    "        for token in doc.tokens:\n",
    "            token.lemmatize(morph_vocab)\n",
    "            if token.text not in russian_stopwords and token.pos in ['NOUN', 'ADJ', 'VERB', 'ADV']:\n",
    "                    lemmas.append(token.lemma)\n",
    "        auth_lemmas.append(lemmas)\n",
    "    return auth_lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "144bddaf2c924fd293eb2a910fb9179f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_sov_list = []\n",
    "for auth in tqdm(soviet):\n",
    "    author = os.path.join('D:\\курсовая_3', auth)\n",
    "    lem = lemm_stories(author)\n",
    "    all_sov_list.extend(lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_sov_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаём словарь и корпус"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = corpora.Dictionary(all_sov_list)\n",
    "texts = all_sov_list\n",
    "corpus4 = [id2word.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('1', 3),\n",
       "  ('1-го', 2),\n",
       "  ('10', 1),\n",
       "  ('11', 3),\n",
       "  ('13', 4),\n",
       "  ('14', 1),\n",
       "  ('14-го', 1),\n",
       "  ('15', 1),\n",
       "  ('15-го', 1),\n",
       "  ('16', 3),\n",
       "  ('16-го', 1),\n",
       "  ('17', 4),\n",
       "  ('17-го', 2),\n",
       "  ('17-ий', 2),\n",
       "  ('18', 1),\n",
       "  ('18-го', 3),\n",
       "  ('19', 1),\n",
       "  ('19-го', 2),\n",
       "  ('19-м', 1),\n",
       "  ('1916', 3),\n",
       "  ('1917', 7),\n",
       "  ('1918', 5),\n",
       "  ('1922', 1),\n",
       "  ('2', 1),\n",
       "  ('2-го', 1),\n",
       "  ('2-е', 1),\n",
       "  ('2-й', 1),\n",
       "  ('20-го', 1),\n",
       "  ('21', 1),\n",
       "  ('21-го', 1),\n",
       "  ('21-дневный', 1),\n",
       "  ('25', 1),\n",
       "  ('25-го', 1),\n",
       "  ('27-го', 1),\n",
       "  ('29', 1),\n",
       "  ('3', 2),\n",
       "  ('6-го', 1),\n",
       "  ('7', 1),\n",
       "  ('8-го', 1),\n",
       "  ('9', 1),\n",
       "  ('i', 1),\n",
       "  ('x', 1),\n",
       "  ('абажур', 4),\n",
       "  ('абсолютно', 6),\n",
       "  ('авдотья', 2),\n",
       "  ('автоклав', 1),\n",
       "  ('автоматический', 1),\n",
       "  ('автомобиль', 1),\n",
       "  ('агроном', 5),\n",
       "  ('адреналин', 1),\n",
       "  ('адрес', 1),\n",
       "  ('аккорд', 2),\n",
       "  ('аккуратно', 1),\n",
       "  ('актер', 1),\n",
       "  ('акушер', 1),\n",
       "  ('акушерка', 30),\n",
       "  ('акушерка-фельдшерица', 1),\n",
       "  ('акушерский', 7),\n",
       "  ('акушерство', 5),\n",
       "  ('акцент', 1),\n",
       "  ('алексеевский', 1),\n",
       "  ('алеть', 1),\n",
       "  ('алый', 3),\n",
       "  ('амбулатория', 3),\n",
       "  ('амбулаторный', 7),\n",
       "  ('ампула', 4),\n",
       "  ('ампутация', 5),\n",
       "  ('амфитеатр', 3),\n",
       "  ('ана', 1),\n",
       "  ('анатомический', 1),\n",
       "  ('анатомия', 1),\n",
       "  ('ангел', 2),\n",
       "  ('ангельский', 1),\n",
       "  ('английский', 2),\n",
       "  ('англичанин', 2),\n",
       "  ('анекдот', 4),\n",
       "  ('антипирин', 1),\n",
       "  ('антракт', 1),\n",
       "  ('апартамент', 1),\n",
       "  ('аппарат', 1),\n",
       "  ('аппенд', 1),\n",
       "  ('аппендицит', 2),\n",
       "  ('апрель', 5),\n",
       "  ('апрельский', 1),\n",
       "  ('аптека', 10),\n",
       "  ('аптечный', 1),\n",
       "  ('арифметика', 1),\n",
       "  ('армия', 1),\n",
       "  ('артериа', 2),\n",
       "  ('артистка', 1),\n",
       "  ('архангельский', 1),\n",
       "  ('аспирин', 1),\n",
       "  ('ассистент', 1),\n",
       "  ('ассистент-фельдшер', 1),\n",
       "  ('асфальт', 1),\n",
       "  ('атлас', 5),\n",
       "  ('атлетический', 1),\n",
       "  ('ах', 3),\n",
       "  ('ахнули', 1),\n",
       "  ('ая', 1),\n",
       "  ('б', 1),\n",
       "  ('баба', 25),\n",
       "  ('бабенка', 1),\n",
       "  ('бабий', 5),\n",
       "  ('бабка', 14),\n",
       "  ('бабочка', 7),\n",
       "  ('багроветь', 1),\n",
       "  ('багровый', 1),\n",
       "  ('байковый', 1),\n",
       "  ('баловаться', 1),\n",
       "  ('балюстрада', 1),\n",
       "  ('бандероль', 1),\n",
       "  ('банка', 2),\n",
       "  ('банный', 1),\n",
       "  ('баночка', 1),\n",
       "  ('баня', 3),\n",
       "  ('барабанить', 2),\n",
       "  ('баралий', 1),\n",
       "  ('бараний', 3),\n",
       "  ('барахло', 1),\n",
       "  ('барашковый', 1),\n",
       "  ('бас', 4),\n",
       "  ('батька', 1),\n",
       "  ('батюшка', 8),\n",
       "  ('батюшки-с-светы', 1),\n",
       "  ('башлык', 5),\n",
       "  ('бег', 1),\n",
       "  ('бегать', 3),\n",
       "  ('бегло', 2),\n",
       "  ('беда', 3),\n",
       "  ('бедность', 1),\n",
       "  ('бедный', 4),\n",
       "  ('бедняга', 1),\n",
       "  ('беднягино', 1),\n",
       "  ('бедро', 8),\n",
       "  ('бежа', 1),\n",
       "  ('бежать', 11),\n",
       "  ('безглазый', 1),\n",
       "  ('безграничный', 2),\n",
       "  ('бездна', 1),\n",
       "  ('бездомный', 1),\n",
       "  ('бездонны', 1),\n",
       "  ('бездорожье', 2),\n",
       "  ('безжизненные', 1),\n",
       "  ('безжизненный', 4),\n",
       "  ('беззвучно', 3),\n",
       "  ('беззвучный', 3),\n",
       "  ('безмятежными', 1),\n",
       "  ('безнадежно', 3),\n",
       "  ('безнадежный', 3),\n",
       "  ('безобразный', 1),\n",
       "  ('безопасный', 2),\n",
       "  ('безотчетный', 1),\n",
       "  ('безукоризненно', 1),\n",
       "  ('безумный', 5),\n",
       "  ('безуспешно', 1),\n",
       "  ('безыскусственный', 1),\n",
       "  ('безэвучный', 1),\n",
       "  ('беленький', 1),\n",
       "  ('белизна', 1),\n",
       "  ('белладонна', 5),\n",
       "  ('бело', 1),\n",
       "  ('беловатые', 1),\n",
       "  ('беловатый', 4),\n",
       "  ('белок', 1),\n",
       "  ('белый', 50),\n",
       "  ('белье', 3),\n",
       "  ('бельишко', 1),\n",
       "  ('берег', 1),\n",
       "  ('бережно', 2),\n",
       "  ('береза', 2),\n",
       "  ('березовый', 1),\n",
       "  ('бес', 1),\n",
       "  ('беседа', 1),\n",
       "  ('беседовать', 1),\n",
       "  ('бесконечно', 1),\n",
       "  ('бесконечный', 3),\n",
       "  ('беспокойнее', 1),\n",
       "  ('беспокойнный', 1),\n",
       "  ('беспокойно', 1),\n",
       "  ('беспокойный', 1),\n",
       "  ('беспокойство', 4),\n",
       "  ('бесполезный', 2),\n",
       "  ('беспомощно', 2),\n",
       "  ('беспомощный', 1),\n",
       "  ('беспорядок', 1),\n",
       "  ('бессвязнее', 1),\n",
       "  ('бессильный', 1),\n",
       "  ('бесследно', 1),\n",
       "  ('бесслезный', 1),\n",
       "  ('бессменный', 1),\n",
       "  ('бессмысленный', 2),\n",
       "  ('бессонница', 1),\n",
       "  ('бессонный', 1),\n",
       "  ('бестолково', 1),\n",
       "  ('бестолковый', 1),\n",
       "  ('бесчисленный', 1),\n",
       "  ('бесшумно', 1),\n",
       "  ('бесшумный', 1),\n",
       "  ('бешено', 1),\n",
       "  ('бешеный', 1),\n",
       "  ('библиотека', 1),\n",
       "  ('библиотечка', 1),\n",
       "  ('биение', 1),\n",
       "  ('биток', 1),\n",
       "  ('битый', 2),\n",
       "  ('бить', 8),\n",
       "  ('биться', 3),\n",
       "  ('бишь', 1),\n",
       "  ('благодарите', 1),\n",
       "  ('благодарить', 6),\n",
       "  ('благодарный', 1),\n",
       "  ('благодетель', 1),\n",
       "  ('благополучно', 5),\n",
       "  ('благополучный', 1),\n",
       "  ('благословение', 1),\n",
       "  ('благословляя', 1),\n",
       "  ('благостный', 1),\n",
       "  ('блаженная', 1),\n",
       "  ('блаженство', 1),\n",
       "  ('бланк', 5),\n",
       "  ('бледнея', 1),\n",
       "  ('бледно', 2),\n",
       "  ('бледность', 1),\n",
       "  ('бледный', 11),\n",
       "  ('блеск', 3),\n",
       "  ('блеснуло', 1),\n",
       "  ('блеснуть', 2),\n",
       "  ('блестяще', 1),\n",
       "  ('блестящий', 8),\n",
       "  ('блеяние', 1),\n",
       "  ('ближе', 1),\n",
       "  ('ближний', 1),\n",
       "  ('близ', 1),\n",
       "  ('близкий', 3),\n",
       "  ('близко', 1),\n",
       "  ('блистательный', 3),\n",
       "  ('блондинка', 1),\n",
       "  ('блуза', 4),\n",
       "  ('бляшка', 1),\n",
       "  ('бог', 4),\n",
       "  ('богатый', 2),\n",
       "  ('бодро', 1),\n",
       "  ('бодрый', 2),\n",
       "  ('боевой', 1),\n",
       "  ('божественный', 3),\n",
       "  ('божий', 1),\n",
       "  ('божок', 1),\n",
       "  ('бой', 6),\n",
       "  ('бойкий', 1),\n",
       "  ('бойко', 1),\n",
       "  ('бок', 5),\n",
       "  ('болезненно', 4),\n",
       "  ('болезненный', 1),\n",
       "  ('болезнь', 25),\n",
       "  ('болеть', 11),\n",
       "  ('болотце', 2),\n",
       "  ('болт', 1),\n",
       "  ('болтаться', 1),\n",
       "  ('боль', 18),\n",
       "  ('больница', 52),\n",
       "  ('больничный', 5),\n",
       "  ('больной', 24),\n",
       "  ('большевик', 5),\n",
       "  ('большевистский', 1),\n",
       "  ('больший', 5),\n",
       "  ('большой', 22),\n",
       "  ('бормотать', 11),\n",
       "  ('борода', 6),\n",
       "  ('бороденка', 4),\n",
       "  ('бородка', 3),\n",
       "  ('бороться', 7),\n",
       "  ('борт', 1),\n",
       "  ('борьба', 3),\n",
       "  ('босой', 3),\n",
       "  ('босяк', 1),\n",
       "  ('ботинок', 2),\n",
       "  ('боязнь', 1),\n",
       "  ('бояться', 12),\n",
       "  ('бранный', 1),\n",
       "  ('брань', 2),\n",
       "  ('брат', 1),\n",
       "  ('брать', 8),\n",
       "  ('браться', 2),\n",
       "  ('браунинг', 6),\n",
       "  ('бревенчатый', 2),\n",
       "  ('бредить', 1),\n",
       "  ('брезгливо', 3),\n",
       "  ('бремя', 2),\n",
       "  ('бритва', 4),\n",
       "  ('брить', 2),\n",
       "  ('бритье', 1),\n",
       "  ('бриться', 6),\n",
       "  ('бровь', 2),\n",
       "  ('бронхит', 1),\n",
       "  ('бросать', 1),\n",
       "  ('бросить', 15),\n",
       "  ('броситься', 4),\n",
       "  ('брюки', 5),\n",
       "  ('брюхо', 2),\n",
       "  ('бу-у', 1),\n",
       "  ('бубнить', 1),\n",
       "  ('бугор', 1),\n",
       "  ('будить', 4),\n",
       "  ('будка', 1),\n",
       "  ('будущий', 1),\n",
       "  ('буйный', 2),\n",
       "  ('бук', 1),\n",
       "  ('буква', 2),\n",
       "  ('бульканье', 1),\n",
       "  ('бумага', 3),\n",
       "  ('бумажник', 1),\n",
       "  ('бумажный', 2),\n",
       "  ('бур', 1),\n",
       "  ('буран', 2),\n",
       "  ('бурно', 1),\n",
       "  ('бурный', 3),\n",
       "  ('бурчать', 1),\n",
       "  ('бурый', 2),\n",
       "  ('буфет', 1),\n",
       "  ('бух', 3),\n",
       "  ('буханий', 1),\n",
       "  ('бухать', 2),\n",
       "  ('бухнуть', 2),\n",
       "  ('бушевать', 1),\n",
       "  ('бывать', 11),\n",
       "  ('бывший', 5),\n",
       "  ('быстро', 10),\n",
       "  ('быстрый', 1),\n",
       "  ('быть', 8),\n",
       "  ('важность', 1),\n",
       "  ('важный', 4),\n",
       "  ('вал', 1),\n",
       "  ('валандаться', 1),\n",
       "  ('валенок', 6),\n",
       "  ('валерьянка', 1),\n",
       "  ('валить', 3),\n",
       "  ('валькирия', 1),\n",
       "  ('валя', 1),\n",
       "  ('валять', 1),\n",
       "  ('валяться', 1),\n",
       "  ('ванна', 8),\n",
       "  ('вар', 1),\n",
       "  ('вата', 2),\n",
       "  ('ваш', 1),\n",
       "  ('вбежать', 3),\n",
       "  ('вблизи', 1),\n",
       "  ('вбок', 1),\n",
       "  ('введение', 1),\n",
       "  ('вверх', 1),\n",
       "  ('вверху', 3),\n",
       "  ('ввести', 3),\n",
       "  ('вводить', 1),\n",
       "  ('вглядываться', 3),\n",
       "  ('вдавлина', 1),\n",
       "  ('вдалеке', 1),\n",
       "  ('вдали', 4),\n",
       "  ('вдаль', 1),\n",
       "  ('вдовец', 3),\n",
       "  ('вдоль', 1),\n",
       "  ('вдохновенно', 4),\n",
       "  ('вдохновенными', 1),\n",
       "  ('вдумываться', 1),\n",
       "  ('вдыхая', 1),\n",
       "  ('ведро', 3),\n",
       "  ('ведьма', 3),\n",
       "  ('вежливо', 2),\n",
       "  ('вежливый', 2),\n",
       "  ('везти', 3),\n",
       "  ('век', 3),\n",
       "  ('веко', 7),\n",
       "  ('велеть', 8),\n",
       "  ('велик', 1),\n",
       "  ('великий', 6),\n",
       "  ('великолепно', 1),\n",
       "  ('великолепный', 2),\n",
       "  ('величественный', 2),\n",
       "  ('величина', 3),\n",
       "  ('венерический', 1),\n",
       "  ('венеролог', 1),\n",
       "  ('венец', 1),\n",
       "  ('вера', 1),\n",
       "  ('вереница', 1),\n",
       "  ('верить', 2),\n",
       "  ('верно', 2),\n",
       "  ('вернуть', 7),\n",
       "  ('вернуться', 13),\n",
       "  ('верный', 10),\n",
       "  ('вероятно', 5),\n",
       "  ('верста', 18),\n",
       "  ('вертеть', 4),\n",
       "  ('вертеться', 3),\n",
       "  ('вертикальный', 3),\n",
       "  ('верх', 2),\n",
       "  ('верхний', 3),\n",
       "  ('верхнний', 1),\n",
       "  ('верхушка', 1),\n",
       "  ('вес', 2),\n",
       "  ('весело', 1),\n",
       "  ('веселый', 3),\n",
       "  ('весенний', 2),\n",
       "  ('весить', 1),\n",
       "  ('веско', 1),\n",
       "  ('весна', 3),\n",
       "  ('вести', 8),\n",
       "  ('весьма', 4),\n",
       "  ('ветвь', 2),\n",
       "  ('ветер', 1),\n",
       "  ('ветчина', 1),\n",
       "  ('веха', 1),\n",
       "  ('вечер', 31),\n",
       "  ('вечерний', 1),\n",
       "  ('вечно', 1),\n",
       "  ('вещество', 1),\n",
       "  ('вещн', 2),\n",
       "  ('вещь', 9),\n",
       "  ('взбеситься', 1),\n",
       "  ('взбудоражить', 1),\n",
       "  ('взвеситься', 1),\n",
       "  ('взволновать', 1),\n",
       "  ('взвыл', 1),\n",
       "  ('взгляд', 6),\n",
       "  ('взглядывать', 1),\n",
       "  ('взглянуть', 3),\n",
       "  ('вздор', 4),\n",
       "  ('вздох', 2),\n",
       "  ('вздохнул', 1),\n",
       "  ('вздохнуть', 3),\n",
       "  ('вздрагивать', 2),\n",
       "  ('вздрогнуть', 4),\n",
       "  ('вздумать', 1),\n",
       "  ('вздуть', 1),\n",
       "  ('вздуться', 2),\n",
       "  ('взламывать', 1),\n",
       "  ('взлом', 1),\n",
       "  ('взмахнуть', 2),\n",
       "  ('взметнуться', 1),\n",
       "  ('взметывать', 1),\n",
       "  ('взмыть', 1),\n",
       "  ('взор', 5),\n",
       "  ('взревел', 1),\n",
       "  ('взрыв', 1),\n",
       "  ('взъерошить', 3),\n",
       "  ('взять', 28),\n",
       "  ('взяться', 6),\n",
       "  ('вид', 14),\n",
       "  ('видать', 4),\n",
       "  ('видеть', 59),\n",
       "  ('видимо', 6),\n",
       "  ('виднеться', 2),\n",
       "  ('видно', 11),\n",
       "  ('видный', 3),\n",
       "  ('визг', 3),\n",
       "  ('визгливый', 1),\n",
       "  ('визгнуть', 1),\n",
       "  ('вилы', 1),\n",
       "  ('винить', 1),\n",
       "  ('виноватый', 8),\n",
       "  ('винт', 2),\n",
       "  ('винтовка', 1),\n",
       "  ('висеть', 10),\n",
       "  ('висок', 2),\n",
       "  ('витрина', 2),\n",
       "  ('вишь', 1),\n",
       "  ('вколачивание', 1),\n",
       "  ('вколоть', 3),\n",
       "  ('вкус', 3),\n",
       "  ('владелец', 1),\n",
       "  ('владеть', 1),\n",
       "  ('влажность', 1),\n",
       "  ('влажный', 1),\n",
       "  ('власть', 1),\n",
       "  ('влево', 1),\n",
       "  ('влезть', 1),\n",
       "  ('влететь', 2),\n",
       "  ('вливание', 1),\n",
       "  ('влияние', 1),\n",
       "  ('вложить', 2),\n",
       "  ('влюбиться', 1),\n",
       "  ('вместе', 2),\n",
       "  ('вначале', 2),\n",
       "  ('внезапно', 1),\n",
       "  ('внеполовый', 1),\n",
       "  ('внешний', 1),\n",
       "  ('внешность', 1),\n",
       "  ('внизу', 8),\n",
       "  ('внимание', 4),\n",
       "  ('внимательно', 4),\n",
       "  ('внимательный', 4),\n",
       "  ('вновь', 8),\n",
       "  ('внутренний', 4),\n",
       "  ('внутренность', 1),\n",
       "  ('внутри', 5),\n",
       "  ('внутрь', 1),\n",
       "  ('внушать', 1),\n",
       "  ('внушительный', 1),\n",
       "  ('вовсе', 7),\n",
       "  ('вогнать', 1),\n",
       "  ('вода', 18),\n",
       "  ('водка', 2),\n",
       "  ('водяной', 1),\n",
       "  ('военный', 1),\n",
       "  ('вожжа', 2),\n",
       "  ('возбужденно', 1),\n",
       "  ('возвести', 2),\n",
       "  ('возврат', 1),\n",
       "  ('возвращаться', 4),\n",
       "  ('возвышение', 1),\n",
       "  ('воздать', 1),\n",
       "  ('воздержание', 5),\n",
       "  ('воздерживаться', 1),\n",
       "  ('воздух', 8),\n",
       "  ('возились', 1),\n",
       "  ('возить', 1),\n",
       "  ('возможно', 2),\n",
       "  ('возможность', 10),\n",
       "  ('возможный', 3),\n",
       "  ('возмужать', 1),\n",
       "  ('возненавидеть', 1),\n",
       "  ('возникать', 1),\n",
       "  ('возникнуть', 5),\n",
       "  ('возница', 18),\n",
       "  ('возня', 2),\n",
       "  ('возобновляться', 1),\n",
       "  ('возрастать', 2),\n",
       "  ('вой', 2),\n",
       "  ('война', 3),\n",
       "  ('войско', 1),\n",
       "  ('войти', 16),\n",
       "  ('вокзал', 1),\n",
       "  ('вокруг', 1),\n",
       "  ('волк', 2),\n",
       "  ('волна', 6),\n",
       "  ('волновать', 1),\n",
       "  ('волноваться', 5),\n",
       "  ('волнообразность', 1),\n",
       "  ('волос', 18),\n",
       "  ('волчий', 2),\n",
       "  ('воля', 3),\n",
       "  ('вон', 8),\n",
       "  ('вона', 1),\n",
       "  ('вонзить', 2),\n",
       "  ('вонзиться', 1),\n",
       "  ('вообш', 1),\n",
       "  ('вообще', 6),\n",
       "  ('вопль', 3),\n",
       "  ('вопрос', 6),\n",
       "  ('вор', 1),\n",
       "  ('ворваться', 4),\n",
       "  ('воровато', 1),\n",
       "  ('воровски', 2),\n",
       "  ('воровской', 2),\n",
       "  ('вороний', 1),\n",
       "  ('ворот', 1),\n",
       "  ('ворота', 5),\n",
       "  ('воротник', 2),\n",
       "  ('ворох', 1),\n",
       "  ('ворочаться', 1),\n",
       "  ('ворчать', 3),\n",
       "  ('восемь', 1),\n",
       "  ('воскликнуть', 6),\n",
       "  ('восклицательный', 1),\n",
       "  ('восклицать', 1),\n",
       "  ('восковой', 3),\n",
       "  ('воспаление', 6),\n",
       "  ('воспалить', 1),\n",
       "  ('воспоминание', 8),\n",
       "  ('воспрещаться', 1),\n",
       "  ('восторг', 1),\n",
       "  ('восторженно', 1),\n",
       "  ('восхищение', 1),\n",
       "  ('вот-вот', 1),\n",
       "  ('воткнуть', 1),\n",
       "  ('вощеный', 1),\n",
       "  ('впервые', 5),\n",
       "  ('вперебой', 1),\n",
       "  ('вперед', 7),\n",
       "  ('впереди', 2),\n",
       "  ('вперить', 1),\n",
       "  ('впечатление', 5),\n",
       "  ('впиваться', 1),\n",
       "  ('вписать', 1),\n",
       "  ('вплотную', 1),\n",
       "  ('вполголоса', 2),\n",
       "  ('вполне', 1),\n",
       "  ('впоследствии', 3),\n",
       "  ('вправить', 1),\n",
       "  ('вправлять', 2),\n",
       "  ('вправо', 1),\n",
       "  ('впрочем', 10),\n",
       "  ('впрыгнуть', 1),\n",
       "  ('впрыскатя', 1),\n",
       "  ('впрыскивание', 9),\n",
       "  ('впрыскивания', 1),\n",
       "  ('впрыскивать', 5),\n",
       "  ('впрысните', 1),\n",
       "  ('впрыснуть', 9),\n",
       "  ('впустую', 1),\n",
       "  ('врать', 1),\n",
       "  ('врач', 50),\n",
       "  ('врач-акушер', 1),\n",
       "  ('врач-практикант', 1),\n",
       "  ('врач-хирург', 1),\n",
       "  ('врачебный', 3),\n",
       "  ('вращали', 1),\n",
       "  ('вред', 2),\n",
       "  ('вредный', 1),\n",
       "  ('временами', 3),\n",
       "  ('время', 50),\n",
       "  ('вручать', 1),\n",
       "  ('вряд', 2),\n",
       "  ('всаживать', 1),\n",
       "  ('все-таки', 1),\n",
       "  ('всегда', 2),\n",
       "  ('всегдашний', 1),\n",
       "  ('всезнающий', 1),\n",
       "  ('вскакивать', 1),\n",
       "  ('вскидывать', 1),\n",
       "  ('вскинуть', 1),\n",
       "  ('вскипятить', 1),\n",
       "  ('вскользнуть', 1),\n",
       "  ('вскоре', 2),\n",
       "  ('вскочить', 3),\n",
       "  ('вскрывать', 1),\n",
       "  ('вскрыть', 2),\n",
       "  ('вслед', 3),\n",
       "  ('вслух', 1),\n",
       "  ('всматривается', 1),\n",
       "  ('всматриваться', 6),\n",
       "  ('всмотреться', 3),\n",
       "  ('всплакнуть', 1),\n",
       "  ('всплеснуть', 1),\n",
       "  ('всплывать', 3),\n",
       "  ('всплыть', 3),\n",
       "  ('вспоминать', 10),\n",
       "  ('вспомнить', 9),\n",
       "  ('вспомниться', 4),\n",
       "  ('вспыхивать', 3),\n",
       "  ('вспыхнуть', 2),\n",
       "  ('вспышка', 2),\n",
       "  ('вставать', 1),\n",
       "  ('вставить', 2),\n",
       "  ('встать', 4),\n",
       "  ('встревожить', 1),\n",
       "  ('встрепенуться', 2),\n",
       "  ('встретить', 6),\n",
       "  ('встреча', 1),\n",
       "  ('встречать', 2),\n",
       "  ('встряхивать', 1),\n",
       "  ('всунуть', 1),\n",
       "  ('всхлипнуть', 1),\n",
       "  ('всхлипывание', 1),\n",
       "  ('всхрапнуть', 1),\n",
       "  ('всюду', 2),\n",
       "  ('всякий', 1),\n",
       "  ('втирание', 4),\n",
       "  ('втирать', 5),\n",
       "  ('втиснуться', 1),\n",
       "  ('вторить', 1),\n",
       "  ('вторично', 1),\n",
       "  ('вторичный', 4),\n",
       "  ('вторник', 2),\n",
       "  ('второстепенный', 1),\n",
       "  ('втроем', 3),\n",
       "  ('втягиваться', 1),\n",
       "  ('втянуть', 2),\n",
       "  ('вход', 1),\n",
       "  ('входить', 1),\n",
       "  ('вцепиться', 2),\n",
       "  ('вчезжать', 1),\n",
       "  ('вчера', 7),\n",
       "  ('вчерашний', 4),\n",
       "  ('вы-с', 1),\n",
       "  ('выбежать', 1),\n",
       "  ('выбелить', 3),\n",
       "  ('выбираться', 2),\n",
       "  ('выбить', 4),\n",
       "  ('выбиться', 1),\n",
       "  ('выбоина', 2),\n",
       "  ('выбрать', 1),\n",
       "  ('выбрить', 1),\n",
       "  ('выбросить', 4),\n",
       "  ('выброситься', 1),\n",
       "  ('вывеска', 1),\n",
       "  ('вывести', 1),\n",
       "  ('вывих', 1),\n",
       "  ('выволочь', 1),\n",
       "  ('выглядеть', 1),\n",
       "  ('выглядывать', 1),\n",
       "  ('выговорить', 3),\n",
       "  ('выдам', 1),\n",
       "  ('выдать', 3),\n",
       "  ('выдаться', 1),\n",
       "  ('выдающийся', 1),\n",
       "  ('выделять', 1),\n",
       "  ('выдержать', 1),\n",
       "  ('выдерживать', 1),\n",
       "  ('выдирать', 1),\n",
       "  ('выдохнуть', 1),\n",
       "  ('выдохнуться', 1),\n",
       "  ('выдумывать', 1),\n",
       "  ('выезд', 1),\n",
       "  ('выехать', 5),\n",
       "  ('выжигать', 1),\n",
       "  ('выжимать', 1),\n",
       "  ('вызвать', 3),\n",
       "  ('вызывать', 1),\n",
       "  ('выйти', 17),\n",
       "  ('выкапывать', 1),\n",
       "  ('выкарабкаться', 1),\n",
       "  ('выкинуть', 1),\n",
       "  ('выключатель', 1),\n",
       "  ('выключить', 1),\n",
       "  ('выкрашенные', 1),\n",
       "  ('выкрикивать', 2),\n",
       "  ('выкрикнуть', 8),\n",
       "  ('вылезать', 2),\n",
       "  ('вылезти', 2),\n",
       "  ('вылететь', 2),\n",
       "  ('вылечить', 1),\n",
       "  ('вылинять', 1),\n",
       "  ('вылить', 1),\n",
       "  ('выломать', 1),\n",
       "  ('вымазать', 2),\n",
       "  ('выманивать', 1),\n",
       "  ('выманить', 1),\n",
       "  ('выметнуться', 1),\n",
       "  ('вымоетесь', 1),\n",
       "  ('вымолвить', 2),\n",
       "  ('вымыть', 1),\n",
       "  ('вымыться', 2),\n",
       "  ('вынести', 1),\n",
       "  ('вынимать', 2),\n",
       "  ('выноси', 1),\n",
       "  ('выносить', 1),\n",
       "  ('вынудить', 1),\n",
       "  ('вынужденный', 1),\n",
       "  ('вынуть', 12),\n",
       "  ('вынырнуть', 2),\n",
       "  ('выпасть', 2),\n",
       "  ('выпевать', 1),\n",
       "  ('выпирать', 1),\n",
       "  ('выписать', 12),\n",
       "  ('выписаться', 1),\n",
       "  ('выписывать', 4),\n",
       "  ('выпить', 4),\n",
       "  ('выпихнуть', 1),\n",
       "  ('выпишу', 1),\n",
       "  ('выплескивать', 1),\n",
       "  ('выплыть', 1),\n",
       "  ('выполнение', 1),\n",
       "  ('выправиться', 1),\n",
       "  ('выпростать', 1),\n",
       "  ('выпуклый', 2),\n",
       "  ('выпуск', 2),\n",
       "  ('выпускать', 1),\n",
       "  ('выпустить', 6),\n",
       "  ('выпученными', 1),\n",
       "  ('выпучить', 1),\n",
       "  ('выработать', 1),\n",
       "  ('выражать', 1),\n",
       "  ('выражаться', 2),\n",
       "  ('выражение', 2),\n",
       "  ('выразительно', 1),\n",
       "  ('выразить', 2),\n",
       "  ('выразиться', 1),\n",
       "  ('вырастать', 1),\n",
       "  ('вырасти', 8),\n",
       "  ('вырвать', 9),\n",
       "  ('вырезать', 2),\n",
       "  ('выровняться', 1),\n",
       "  ('выручать', 1),\n",
       "  ('высадиться', 1),\n",
       "  ('высвободить', 1),\n",
       "  ('высидеть', 1),\n",
       "  ('выскакивать', 2),\n",
       "  ('выскочить', 7),\n",
       "  ('выслать', 1),\n",
       "  ('выслушать', 2),\n",
       "  ('высокий', 3),\n",
       "  ('высоко', 1),\n",
       "  ('высохший', 1),\n",
       "  ('выспаться', 1),\n",
       "  ('выстрел', 1),\n",
       "  ('выстрелить', 1),\n",
       "  ('выступать', 4),\n",
       "  ('выступить', 5),\n",
       "  ('высунуть', 1),\n",
       "  ('высыхать', 2),\n",
       "  ('высь', 1),\n",
       "  ('вытарашить', 1),\n",
       "  ('вытаскать', 1),\n",
       "  ('вытаскивать', 1),\n",
       "  ('вытащить', 1),\n",
       "  ('вытереть', 7),\n",
       "  ('вытерпеть', 6),\n",
       "  ('вытечь', 3),\n",
       "  ('вытирать', 4),\n",
       "  ('вытолкнуть', 1),\n",
       "  ('выть', 7),\n",
       "  ('вытягиваться', 1),\n",
       "  ('вытянулись', 1),\n",
       "  ('вытянуть', 1),\n",
       "  ('выудить', 1),\n",
       "  ('выучиться', 2),\n",
       "  ('выход', 1),\n",
       "  ('выходить', 6),\n",
       "  ('вычистка', 1),\n",
       "  ('вычура', 1),\n",
       "  ('выше', 1),\n",
       "  ('вышитый', 1),\n",
       "  ('выщербить', 1),\n",
       "  ('выэвалить', 1),\n",
       "  ('выясниться', 1),\n",
       "  ('вьюга', 12),\n",
       "  ('вьюги', 1),\n",
       "  ('вьюжный', 3),\n",
       "  ('вьются', 1),\n",
       "  ('вязать', 1),\n",
       "  ('вяло', 1),\n",
       "  ('вялый', 2),\n",
       "  ('гаворить', 1),\n",
       "  ('газ', 1),\n",
       "  ('газета', 8),\n",
       "  ('галлюцинация', 6),\n",
       "  ('галстук', 2),\n",
       "  ('галун', 2),\n",
       "  ('галунный', 1),\n",
       "  ('гангрена', 2),\n",
       "  ('гармошка', 2),\n",
       "  ('гаснуть', 1),\n",
       "  ('гвоздь', 1),\n",
       "  ('где', 7),\n",
       "  ('где-нибудь', 1),\n",
       "  ('где-то', 15),\n",
       "  ('геморрой', 1),\n",
       "  ('гениальный', 1),\n",
       "  ('германский', 2),\n",
       "  ('герой', 1),\n",
       "  ('гетры', 1),\n",
       "  ('гигантский', 3),\n",
       "  ('гимназическ', 1),\n",
       "  ('гинекологический', 1),\n",
       "  ('гипс', 1),\n",
       "  ('гипсовые', 1),\n",
       "  ('гипсовый', 3),\n",
       "  ('главный', 14),\n",
       "  ('гладить', 1),\n",
       "  ('гладкий', 3),\n",
       "  ('гладко', 2),\n",
       "  ('глаз', 123),\n",
       "  ('глазал', 1),\n",
       "  ('глазок', 4),\n",
       "  ('глотать', 3),\n",
       "  ('глотка', 10),\n",
       "  ('глотку', 1),\n",
       "  ('глоток', 2),\n",
       "  ('глубина', 3),\n",
       "  ('глубокий', 2),\n",
       "  ('глубоко', 4),\n",
       "  ('глубокомысленно', 1),\n",
       "  ('глупее', 1),\n",
       "  ('глупо', 1),\n",
       "  ('глупый', 6),\n",
       "  ('глухо', 10),\n",
       "  ('глухой', 8),\n",
       "  ('глуше', 3),\n",
       "  ('глушь', 12),\n",
       "  ('глядеть', 16),\n",
       "  ('глядя', 1),\n",
       "  ('глянец', 1),\n",
       "  ('глянуть', 12),\n",
       "  ('глянцевитый', 1),\n",
       "  ('гм', 1),\n",
       "  ('гнать', 1),\n",
       "  ('гнев', 1),\n",
       "  ('гневно', 1),\n",
       "  ('гнездиться', 1),\n",
       "  ('гнилой', 3),\n",
       "  ('гной', 1),\n",
       "  ('гнойник', 3),\n",
       "  ('гнойный', 3),\n",
       "  ('го', 3),\n",
       "  ('гобелен', 2),\n",
       "  ('говорить', 69),\n",
       "  ('говорящий', 1),\n",
       "  ('год', 82),\n",
       "  ('годиться', 2),\n",
       "  ('годовалый', 1),\n",
       "  ('голень', 2),\n",
       "  ('голенький', 2),\n",
       "  ('голландка-печка', 1),\n",
       "  ('голландка-печь', 1),\n",
       "  ('голова', 52),\n",
       "  ('головка', 2),\n",
       "  ('голодать', 1),\n",
       "  ('голокожий', 1),\n",
       "  ('голос', 58),\n",
       "  ('голосок', 1),\n",
       "  ('голубоватее', 1),\n",
       "  ('голубоватый', 1),\n",
       "  ('голубой', 3),\n",
       "  ('голубчик', 2),\n",
       "  ('голый', 1),\n",
       "  ('гонка', 1),\n",
       "  ('гонять', 1),\n",
       "  ('гора', 2),\n",
       "  ('гораздо', 2),\n",
       "  ('горб', 1),\n",
       "  ('горбатый', 1),\n",
       "  ('горделиво', 2),\n",
       "  ('горделивый', 1),\n",
       "  ('гордиться', 3),\n",
       "  ('гордо', 1),\n",
       "  ('гордость', 4),\n",
       "  ('гордый', 3),\n",
       "  ('горе', 2),\n",
       "  ('горелка', 1),\n",
       "  ('гореловский', 4),\n",
       "  ('гореловый', 1),\n",
       "  ('горесть', 1),\n",
       "  ('гореть', 14),\n",
       "  ('горка', 2),\n",
       "  ('горло', 31),\n",
       "  ('город', 31),\n",
       "  ('городок', 3),\n",
       "  ('горох', 1),\n",
       "  ('горошек', 1),\n",
       "  ('горошина', 1),\n",
       "  ('горчишник', 5),\n",
       "  ('горький', 1),\n",
       "  ('горячий', 2),\n",
       "  ('горячка', 1),\n",
       "  ('госпиталь', 1),\n",
       "  ('господин', 3),\n",
       "  ('господь', 2),\n",
       "  ('гость', 3),\n",
       "  ('государственный', 2),\n",
       "  ('готовить', 6),\n",
       "  ('готовый', 3),\n",
       "  ('градус', 1),\n",
       "  ('градусник', 1),\n",
       "  ('гражданин', 6),\n",
       "  ('грамм', 5),\n",
       "  ('грамотный', 1),\n",
       "  ('грандиозный', 1),\n",
       "  ('граница', 2),\n",
       "  ('графа', 1),\n",
       "  ('гребень', 1),\n",
       "  ('гребешок', 1),\n",
       "  ('греметь', 4),\n",
       "  ('грех', 1),\n",
       "  ('гримаса', 1),\n",
       "  ('гроб', 2),\n",
       "  ('гробовой', 1),\n",
       "  ('гроза', 2),\n",
       "  ('грозд', 1),\n",
       "  ('грозить', 1),\n",
       "  ('грозно', 1),\n",
       "  ('грозный', 10),\n",
       "  ('гром', 1),\n",
       "  ('громаден', 1),\n",
       "  ('громадный', 13),\n",
       "  ('громко', 3),\n",
       "  ('громоздиться', 1),\n",
       "  ('громоздямися', 1),\n",
       "  ('громыхаюший', 1),\n",
       "  ('громыхая', 2),\n",
       "  ('грохнуть', 1),\n",
       "  ('грохот', 2),\n",
       "  ('грохотать', 1),\n",
       "  ('грош', 1),\n",
       "  ('грубо', 1),\n",
       "  ('грубость', 1),\n",
       "  ('грубый', 2),\n",
       "  ('груда', 3),\n",
       "  ('грудной', 1),\n",
       "  ('грудь', 27),\n",
       "  ('груз', 1),\n",
       "  ('груздь', 1),\n",
       "  ('грыжа', 18),\n",
       "  ('грыжевый', 1),\n",
       "  ('грызня', 2),\n",
       "  ('грызть', 2),\n",
       "  ('грязно-пепельный', 1),\n",
       "  ('грязь', 1),\n",
       "  ('гу', 5),\n",
       "  ('гу-у', 1),\n",
       "  ('губа', 11),\n",
       "  ('губерния', 2),\n",
       "  ('губите', 1),\n",
       "  ('губка', 1),\n",
       "  ('гудеть', 1),\n",
       "  ('гуж', 1),\n",
       "  ('гул', 1),\n",
       "  ('гулкий', 1),\n",
       "  ('гумма', 1),\n",
       "  ('гуммозный', 1),\n",
       "  ('гусек', 2),\n",
       "  ('густой', 5),\n",
       "  ...]]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[(id2word[id], freq) for id, freq in cp] for cp in corpus4[:1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тренируем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus4,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=10, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Записываем результаты в файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Советские топики.txt', 'a', encoding='utf-8') as f:\n",
    "    for topic in lda_model.print_topics():\n",
    "        f.write(str(topic[0])+' - '+str(topic[-1])+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Писатели-эмигранты после эмиграции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78030f4468814c00b289bd4a98d1a563",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "all_emig_after_list = []\n",
    "for auth in tqdm(emig):\n",
    "    author_all = os.path.join('D:\\курсовая_3', auth)\n",
    "    author = os.path.join(author_all, 'после эмиграции')\n",
    "    lem = lemm_stories(author)\n",
    "    all_emig_after_list.extend(lem)\n",
    "print(len(all_emig_after_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаём словарь и корпус"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = corpora.Dictionary(all_emig_after_list)\n",
    "texts = all_emig_after_list\n",
    "corpus5 = [id2word.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тренируем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model2 = gensim.models.ldamodel.LdaModel(corpus=corpus5,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=10, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Записываем результаты в файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Эмигрантские_после топики.txt', 'a', encoding='utf-8') as f:\n",
    "    for topic in lda_model2.print_topics():\n",
    "        f.write(str(topic[0])+' - '+str(topic[-1])+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Писатели-эмигранты до эмиграции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0147b36f6ffe415d91e26c95a4287a96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "all_emig_before_list = []\n",
    "for auth in tqdm(emig):\n",
    "    author_all = os.path.join('D:\\курсовая_3', auth)\n",
    "    author = os.path.join(author_all, 'до эмиграции')\n",
    "    lem = lemm_stories(author)\n",
    "    all_emig_before_list.extend(lem)\n",
    "print(len(all_emig_before_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаём словарь и корпус"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = corpora.Dictionary(all_emig_before_list)\n",
    "texts = all_emig_before_list\n",
    "corpus6 = [id2word.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тренируем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model3 = gensim.models.ldamodel.LdaModel(corpus=corpus6,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=10, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Записываем результаты в файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Эмигрантские_до топики.txt', 'a', encoding='utf-8') as f:\n",
    "    for topic in lda_model3.print_topics():\n",
    "        f.write(str(topic[0])+' - '+str(topic[-1])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
